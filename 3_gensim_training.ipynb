{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "* change to space splitted basis.\n",
    "* remove duplicate rows and rows that consist too few element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30567\n",
      "30573 \n",
      "\n",
      "614\n",
      "617\n"
     ]
    }
   ],
   "source": [
    "# prepare data by concating original and removed stopwords together\n",
    "original = pd.read_csv(\"./datasets/3_original_text.csv\", sep='\\t')\n",
    "original_stopwords_removed = pd.read_csv(\"./datasets/8_original_text_only_stopwords_removed.csv\")\n",
    "\n",
    "retweet = pd.read_csv(\"./datasets/5_retweet_text.csv\", sep='\\t')\n",
    "retweet_stopwords_removed = pd.read_csv(\"./datasets/7_retweet_text_only_stopwords_removed.csv\")\n",
    "\n",
    "print(len(original))\n",
    "print(len(original_stopwords_removed), '\\n')\n",
    "\n",
    "print(len(retweet))\n",
    "print(len(retweet_stopwords_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Gensim Models - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec model by genism, with data: text8\n",
    "dataset = api.load('text8')\n",
    "data = [d for d in dataset]\n",
    "\n",
    "# train word2vec model. Default result vector size = 100\n",
    "model = Word2Vec(data, min_count=0, workers=cpu_count())\n",
    "\n",
    "model.save('./gensim_models/word2vec_model_text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29335767  0.28058144  1.2209277   0.07219032 -0.05433149 -0.75027883\n",
      " -0.4756051   0.6269139   1.3665643   0.40384582  0.05331578  3.0478833\n",
      " -0.23827238 -0.5766506   1.3480146   0.37904382 -1.0335796  -0.39224458\n",
      " -0.5516785  -2.4345887   1.5142587  -1.7600015   2.6333845   0.81366205\n",
      " -1.789157   -0.38301036 -0.22012158  1.6440449   0.3503979   0.19041426\n",
      "  1.0791503   0.33977607 -1.8347809  -0.22882211  1.3318431   1.7158645\n",
      " -1.1213557  -0.7003229  -0.03556969  1.3839508   1.5685267   1.8462223\n",
      " -0.82925093 -1.0604658   2.3780234   2.0007992   0.2151887   0.37229872\n",
      "  0.3029396   1.9708436   0.02968904  0.2803673  -0.59055823  1.0669053\n",
      " -3.4616804  -1.2851304  -0.08825423 -2.2606418   0.2032655  -1.591786\n",
      "  0.491039   -2.1102717  -1.6018078  -1.8387545  -3.0239727   1.358315\n",
      " -1.4806606   0.38066745  0.6768085  -0.04849679 -0.45524392  0.54454654\n",
      " -0.11318853  1.3164388  -3.3580596  -2.1648653   1.4636595  -0.47797066\n",
      "  0.7874879  -2.0791008   1.3310676  -1.0626041  -0.12971972 -0.24798861\n",
      " -2.6320298   0.83313334 -0.17041117  0.6986863  -0.4694295  -0.2245793\n",
      "  0.69752765 -1.6057047  -2.0271587   0.66034055 -1.7022111   0.6476899\n",
      "  1.5200748  -0.8960348   0.00481058 -0.5784295 ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1089915   1.0811623   2.3474104  -0.55616593  0.26091388 -0.01272155\n",
      " -0.0440357   0.3969774   0.47158262 -0.27898347  0.37743673  3.552992\n",
      " -0.12242752  0.7295136   2.4407167  -0.7377162  -1.472729   -0.9631364\n",
      "  0.01176887 -4.289425    0.19752944 -1.5961907   2.4035223   0.8474022\n",
      " -2.340774    0.50361663  0.97131807  1.5991626  -0.14529449  0.41963005\n",
      "  1.2242484   0.03783995 -1.5423788  -0.6744898   2.7246504   2.675622\n",
      " -1.3893353   0.03956841 -1.3028386   0.0444745   1.7526083  -0.12947257\n",
      " -1.6173276  -1.1814826   3.217433    3.2263916   0.0722702   0.65972334\n",
      "  0.17476656  0.6797268   0.31193396  0.5565776   0.5646045   1.6013293\n",
      " -2.6540806  -1.4334471  -0.7155246  -1.8489497   0.2911522  -2.9275587\n",
      "  2.1606739  -2.7786162  -1.5501636  -2.6636703  -3.3433623   2.4798617\n",
      " -1.540462   -0.2769955   0.33075973 -1.2379001  -0.5476088   0.18099673\n",
      "  1.7869911   1.3287969  -2.5871916  -1.758952    2.1117709  -2.1903632\n",
      "  1.2822893  -1.5170217   1.2226784   0.18040963  1.3632056  -0.39794776\n",
      " -2.8386009   2.1890593  -1.9895235   0.9819684   0.39257607 -0.8874754\n",
      "  0.5144981  -2.023175   -2.8116887   0.35533327 -0.84268427  0.8008432\n",
      "  1.9569654  -1.2075919   1.2403346   0.24422769]\n"
     ]
    }
   ],
   "source": [
    "# update our model with tweet dataset\n",
    "\n",
    "# create copora dictionary\n",
    "tweet_data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "data_list = tweet_data.iloc[:, 0].tolist()\n",
    "# tokenize data into words\n",
    "texts = [[text for text in tweet.split()] for tweet in data_list]\n",
    "# create dictionary by copora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(type(dictionary))\n",
    "print(type(texts))\n",
    "\n",
    "\n",
    "# load text8 word2vec dataset\n",
    "model = Word2Vec.load('./gensim_models/word2vec_model_text8')\n",
    "print(model['media'], '\\n')\n",
    "\n",
    "# update the model with tweets dataset\n",
    "model.build_vocab(texts, update=True)\n",
    "model.train(data, total_examples=model.corpus_count, epochs=model.iter)\n",
    "print(model['media'])\n",
    "\n",
    "# save the model\n",
    "model.save('./gensim_models/word2vec_model_text8_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\ricardo\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45001727  1.3712811  -1.4018998  -0.3164949   1.43814    -0.46061862\n",
      "  1.7951301  -1.3389441  -0.3716764   0.14157812  0.18296227  0.89215726\n",
      " -0.55301917 -0.7416799   0.08464012  1.1770823   1.1846385  -1.847964\n",
      "  1.055039   -1.0630884   1.2606027   0.09914911 -0.38686594  0.8529165\n",
      "  0.5230799  -0.09052169  0.62078506 -0.14445329  1.092101    0.69675726\n",
      " -1.0820731   2.1068718  -1.8636477  -0.6896987   0.19457495 -2.0239112\n",
      "  0.3551969  -2.0342014  -1.1496129   0.38238797  0.5103979   0.45153382\n",
      " -0.33121938  0.7251955   1.2568774   0.73351043  1.1155524  -0.03670964\n",
      " -0.7239386   1.0504031  -0.42432594 -0.9509309  -1.1322044  -0.6511916\n",
      " -0.45762008  0.33608925  0.5772421  -0.2521093  -1.3886068   0.8997238\n",
      " -0.995965   -1.2804515   0.8375072   1.2667991   0.4125759   1.1231145\n",
      " -1.3068154   0.41948798 -1.1549307   0.54176843 -1.7674714   1.437072\n",
      " -0.3455198   0.9392271   0.5950211   1.2404965  -0.45126772  0.09859371\n",
      "  0.8435631  -0.17199157 -0.08756505  0.5246988  -0.76778793 -1.2086359\n",
      " -0.45003468  0.7339175   0.62750244 -0.04506618  0.6633076   1.422053\n",
      "  0.28179026 -1.4853638  -0.6134598  -0.02640666 -0.6980098   0.2734103\n",
      "  0.792361    1.3695405  -0.92543596 -0.3013688 ] \n",
      "\n",
      "[ 0.51067126  1.3447353  -1.1074457   0.3249483   0.45884514 -0.5795688\n",
      "  1.5242664  -0.77402025 -0.0435553   0.55572754 -0.2799028   0.42240268\n",
      " -0.51202977 -0.7520289   0.46385974  0.90501994  0.75956416 -1.0433328\n",
      "  1.0819046  -0.8013448   0.7581144   0.28761506 -1.0428174   0.75726044\n",
      " -0.3834507  -0.01328668  0.2275049  -0.2970596   1.0228566   0.9402161\n",
      " -1.6435691   2.0421484  -1.3657305  -0.90187764  0.24734904 -1.7524667\n",
      " -0.13711865 -2.1666055  -0.69930255  0.08801074  0.5243936   0.17493986\n",
      " -0.63864416  0.5285479   1.3113872   0.9505992   1.1699163  -0.15848882\n",
      " -0.6506112   0.5684299   0.06571174 -0.6222705  -0.90152305 -0.90260774\n",
      " -0.54899985 -0.569965   -0.08937683  0.5105367  -0.77297723  1.2176923\n",
      " -0.26167068 -0.7582398   0.2011349   1.0344663  -0.1781115   1.1761981\n",
      " -1.3105496   0.12081477 -0.37272266  0.59765685 -1.5173901   1.4439462\n",
      " -0.66140217  1.1704628   0.8044526   1.860861   -0.23482196 -0.04026641\n",
      "  0.6575749  -0.6494932   0.5468779   0.41953835 -0.4583487  -0.98869526\n",
      "  0.45706192  0.2720081   0.8200873   0.8741202   0.21983716  1.4711266\n",
      " -0.26524186 -0.81016725 -0.5645369   0.10783045 -1.3563552  -0.6918546\n",
      "  1.0760792   0.2752563  -0.87008846 -0.05960485]\n"
     ]
    }
   ],
   "source": [
    "# train a word2vec model with tweet dataset only\n",
    "\n",
    "# create copora dictionary\n",
    "tweet_data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "data_list = tweet_data.iloc[:, 0].tolist()\n",
    "# tokenize data into words\n",
    "texts = [[text for text in tweet.split()] for tweet in data_list]\n",
    "# create dictionary by copora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(type(dictionary))\n",
    "print(type(texts))\n",
    "\n",
    "# train word2vec model. Default result vector size = 100\n",
    "model = Word2Vec(texts, min_count=0, workers=cpu_count())\n",
    "print(model['trump'], '\\n')\n",
    "print(model['taiwan'])\n",
    "\n",
    "model.save('./gensim_models/word2vec_model_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('j', 0.9450893998146057), ('endorses', 0.9430126547813416), ('ttle', 0.9411283731460571), ('ot', 0.9399396181106567), ('telephone', 0.9292389154434204), ('melaniebatley', 0.9265999794006348), ('kpphotography38', 0.9255761504173279), ('sheriffclarke', 0.9241675138473511), ('gladly', 0.9209092259407043), ('bonanza', 0.9208433628082275)] \n",
      "\n",
      "[('call', 0.9987192153930664), ('taiwans', 0.9980147480964661), ('praises', 0.994354784488678), ('considering', 0.9931445121765137), ('operative', 0.9931440353393555), ('jennifer75ar', 0.9929768443107605), ('endorse', 0.9920759797096252), ('headed', 0.9918076992034912), ('congratulatory', 0.9910873174667358), ('risks', 0.9909263253211975)] \n",
      "\n",
      "[('china', 0.9863436222076416), ('eligible', 0.9777646064758301), ('cronies', 0.9762970209121704), ('wants', 0.9760562181472778), ('neither', 0.9753323793411255), ('trap', 0.9737012982368469), ('barack', 0.9723501801490784), ('said', 0.9715273380279541), ('tougher', 0.9713266491889954), ('never', 0.9688180685043335)] \n",
      "\n",
      "[('bentechpro', 0.8147005438804626), ('vpbidens', 0.8145315051078796), ('sovereign', 0.8130879998207092), ('makeamericasafeagain', 0.8107984066009521), ('forward2016', 0.8099133968353271), ('mpeach', 0.8081022500991821), ('beneath', 0.8081014156341553), ('virtue', 0.8080786466598511), ('craigbbannister', 0.8073309659957886), ('immortals', 0.8067179918289185)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the result with only tweets data\n",
    "print(model.wv.most_similar('trump'), '\\n')\n",
    "print(model.wv.most_similar('taiwan'), '\\n')\n",
    "print(model.wv.most_similar('obama'), '\\n')\n",
    "print(model.wv.most_similar('freak'), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Training - Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create 'tagged document'\n",
    "def create_tagged_document(list_of_list_of_word):\n",
    "    for i, list_of_word in enumerate(list_of_list_of_word):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_word, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'tagged document' dataset of text8\n",
    "# load text8 dataset\n",
    "dataset = api.load('text8')\n",
    "data = [d for d in dataset]\n",
    "\n",
    "# create tagged document of text8\n",
    "training_data_text8 = list(create_tagged_document(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize doc2vec model\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(training_data_text8)\n",
    "\n",
    "# train the Doc2Vec model\n",
    "model.train(training_data_text8, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "model.save('./gensim_models/doc2vec_model_text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with text8 and tweets data\n",
    "tweet_data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "data_list = tweet_data.iloc[:, 0].tolist()\n",
    "\n",
    "# tokenize data into words\n",
    "training_tweet = [[text for text in tweet.split()] for tweet in data_list]\n",
    "\n",
    "# create tagged document with text8 and tweet\n",
    "training_data_text8_tweet = list(create_tagged_document(data + training_tweet))\n",
    "\n",
    "# create tagged document with tweet only\n",
    "training_data_tweet = list(create_tagged_document(training_tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model for both text8 and tweets data\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(training_data_text8_tweet)\n",
    "\n",
    "# train the model\n",
    "model.train(training_data_text8_tweet, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "model.save('./gensim_models/doc2vec_model_text8_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model for only tweets\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=100)\n",
    "\n",
    "# build the vocabulary\n",
    "model.build_vocab(training_data_tweet)\n",
    "\n",
    "# train the model\n",
    "model.train(training_data_tweet, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "model.save('./gensim_models/doc2vec_model_tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset with Doc2Vec Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29503/29503 [11:58<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet   feature_0  feature_1  \\\n",
      "0  nytimes thrilled obama talking communist dicta...   0.348161   0.615191   \n",
      "1  oops thehill trump breaks decades us protocol ...   0.692293   1.457361   \n",
      "2  donald trumpcall taiwan president surprise off...   0.047654   1.325182   \n",
      "3                   so trump spoke president taiwan    0.421363  -0.144011   \n",
      "4           trumps wants build hotel resorts taiwan   -0.004827  -0.469450   \n",
      "\n",
      "   feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
      "0   0.795454   0.357206  -0.998866   0.953924   2.428413   0.342467   \n",
      "1  -0.443985   0.495889  -1.006637   0.606732  -0.010881  -0.882323   \n",
      "2  -1.248984   0.791980   0.285409   0.132241  -0.480756   0.217926   \n",
      "3  -0.348768   0.858688   0.064211  -0.977771   0.110473  -0.594468   \n",
      "4  -0.484037   0.507383   0.140597  -0.207009   0.357401  -1.492848   \n",
      "\n",
      "   feature_8  ...  feature_40  feature_41  feature_42  feature_43  feature_44  \\\n",
      "0   2.068511  ...    1.362662   -0.472362   -0.569589   -0.061905    1.050716   \n",
      "1   1.501403  ...    0.824284    0.323833    0.581383    0.846659    2.144461   \n",
      "2   1.002424  ...    0.280340    0.081734   -0.342736   -0.256397    0.617811   \n",
      "3  -0.125367  ...   -0.518526    0.047186   -0.058803    0.194372    0.374230   \n",
      "4   0.684160  ...    0.117831    0.129305   -0.397862   -0.637809    0.328885   \n",
      "\n",
      "   feature_45  feature_46  feature_47  feature_48  feature_49  \n",
      "0    0.925287    2.737500    1.263742   -2.843178   -1.084122  \n",
      "1    0.252443    0.205135   -1.332468   -0.191828   -0.746453  \n",
      "2    0.813720    0.221275   -0.483809    0.440118   -2.001576  \n",
      "3    0.314513    1.015976   -0.146177   -1.152854   -0.738223  \n",
      "4    0.066646    0.696552   -0.393625   -0.263937   -0.996697  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "          feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean       0.346780      0.473012     -0.506967      0.329587     -0.410561   \n",
      "std        0.669472      0.780428      0.697670      0.681444      0.577178   \n",
      "min       -2.382749     -4.280070     -5.215570     -2.444786     -3.767659   \n",
      "25%       -0.079423     -0.007723     -0.936719     -0.112757     -0.752077   \n",
      "50%        0.287514      0.427592     -0.456678      0.254046     -0.373231   \n",
      "75%        0.751718      0.957938     -0.038994      0.736505     -0.052266   \n",
      "max        4.084274      3.989234      2.553890      3.772254      2.972640   \n",
      "\n",
      "          feature_5     feature_6     feature_7     feature_8     feature_9  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean      -0.287208      0.185518     -0.536969      1.006111     -0.160846   \n",
      "std        0.650175      0.756032      0.748500      0.764294      0.604796   \n",
      "min       -3.311094     -3.133171     -4.007431     -3.403554     -4.018921   \n",
      "25%       -0.674681     -0.293740     -0.992526      0.540063     -0.521122   \n",
      "50%       -0.264066      0.118775     -0.527976      0.991147     -0.124259   \n",
      "75%        0.103957      0.633776     -0.096287      1.482335      0.200041   \n",
      "max        2.979028      3.929090      3.550609      4.408858      2.655037   \n",
      "\n",
      "       ...    feature_40    feature_41    feature_42    feature_43  \\\n",
      "count  ...  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean   ...      0.502524      0.245423      0.202643      0.207932   \n",
      "std    ...      0.655392      0.662490      0.652864      0.704384   \n",
      "min    ...     -2.479803     -2.950761     -2.855535     -4.013336   \n",
      "25%    ...      0.107360     -0.145005     -0.185125     -0.202751   \n",
      "50%    ...      0.461240      0.213353      0.160410      0.259334   \n",
      "75%    ...      0.898910      0.610107      0.585309      0.647365   \n",
      "max    ...      4.016295      4.139955      3.360780      3.154799   \n",
      "\n",
      "         feature_44    feature_45    feature_46    feature_47    feature_48  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean      -0.180684     -0.154646     -0.039304     -0.274549     -0.306435   \n",
      "std        0.740947      0.706979      0.722051      0.776729      0.710561   \n",
      "min       -3.322238     -3.245550     -3.787616     -3.869065     -4.464083   \n",
      "25%       -0.688948     -0.583679     -0.530582     -0.767655     -0.733491   \n",
      "50%       -0.242479     -0.185671     -0.102986     -0.324004     -0.301787   \n",
      "75%        0.268333      0.268879      0.409229      0.176440      0.121310   \n",
      "max        4.948190      3.318911      3.586354      3.737340      3.302467   \n",
      "\n",
      "         feature_49  \n",
      "count  29503.000000  \n",
      "mean      -0.925382  \n",
      "std        0.844189  \n",
      "min       -5.100451  \n",
      "25%       -1.412943  \n",
      "50%       -0.806233  \n",
      "75%       -0.338481  \n",
      "max        2.718674  \n",
      "\n",
      "[8 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# load original dataset\n",
    "data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "\n",
    "# load text8 dataset\n",
    "model = gensim.models.doc2vec.Doc2Vec.load('./gensim_models/doc2vec_model_text8')\n",
    "\n",
    "for i, j in enumerate(tqdm(data.iloc[:, 0])):\n",
    "    element_splitted = j.split(\" \")\n",
    "    feature_array = model.infer_vector(element_splitted)\n",
    "    for a, b in enumerate(feature_array):\n",
    "        column_name = 'feature_' + str(a)\n",
    "        data.loc[i, column_name] = b\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "data.to_csv('./datasets/tweets_doc2vec_text8.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29503/29503 [12:31<00:00, 39.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet   feature_0  feature_1  \\\n",
      "0  nytimes thrilled obama talking communist dicta...  -0.369244   0.181638   \n",
      "1  oops thehill trump breaks decades us protocol ...   0.065730   0.521660   \n",
      "2  donald trumpcall taiwan president surprise off...   0.231041   0.394100   \n",
      "3                   so trump spoke president taiwan   -0.440544  -0.126384   \n",
      "4           trumps wants build hotel resorts taiwan   -0.105632  -0.220953   \n",
      "\n",
      "   feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
      "0   1.199271   1.279223  -0.193409  -0.074453   1.482049  -0.136166   \n",
      "1  -0.665984   0.051890  -0.008099   0.315365   0.130044  -0.483743   \n",
      "2  -0.259289  -0.323162   0.210678   0.293607  -0.184777   0.388177   \n",
      "3   0.355273  -0.034865   0.327677  -0.417089  -0.099206  -0.271834   \n",
      "4  -0.139125  -0.101333   0.170080   0.242618   0.257020  -0.321792   \n",
      "\n",
      "   feature_8  ...  feature_40  feature_41  feature_42  feature_43  feature_44  \\\n",
      "0   1.215607  ...    0.310457   -0.290413   -0.373764   -0.063297    0.329606   \n",
      "1   0.491653  ...    0.384999    1.411220    0.702050    0.019298    0.769528   \n",
      "2   0.437087  ...    0.243391    0.728979    0.366799    0.322573    0.104728   \n",
      "3   0.396755  ...   -0.011125   -0.132677    0.139783    0.405004   -0.346146   \n",
      "4   0.836725  ...   -0.113353    0.057455    0.041232    0.112656   -0.445557   \n",
      "\n",
      "   feature_45  feature_46  feature_47  feature_48  feature_49  \n",
      "0    0.875672   -0.096002    0.329214   -1.023320   -1.217253  \n",
      "1    0.530178   -0.969804   -0.899067    0.248349   -0.270434  \n",
      "2   -0.465498   -0.246988   -0.357633   -0.002767   -0.153551  \n",
      "3   -0.547570   -0.097663   -0.979185   -0.489581    0.109367  \n",
      "4   -0.863033   -0.572736   -1.273268   -0.580579   -0.197701  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "          feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean       0.177060     -0.038156      0.098197     -0.286027      0.191018   \n",
      "std        0.527514      0.567892      0.556140      0.534807      0.476831   \n",
      "min       -2.472542     -3.026340     -2.840422     -2.931688     -2.270871   \n",
      "25%       -0.144336     -0.372555     -0.218053     -0.600451     -0.076819   \n",
      "50%        0.130476     -0.040945      0.090805     -0.294292      0.174428   \n",
      "75%        0.490212      0.276800      0.400723      0.002714      0.461983   \n",
      "max        3.103523      3.011589      2.945667      2.541981      2.721294   \n",
      "\n",
      "          feature_5     feature_6     feature_7     feature_8     feature_9  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean       0.112773      0.339140     -0.230174      0.742398      0.060319   \n",
      "std        0.546295      0.522919      0.610140      0.537075      0.462076   \n",
      "min       -2.988695     -2.047061     -3.766634     -1.954788     -2.350473   \n",
      "25%       -0.199675      0.018728     -0.585008      0.418980     -0.190262   \n",
      "50%        0.081478      0.295831     -0.214267      0.725731      0.052356   \n",
      "75%        0.429533      0.635706      0.114557      1.073084      0.310280   \n",
      "max        3.361856      3.243308      3.502303      3.254675      2.754119   \n",
      "\n",
      "       ...    feature_40    feature_41    feature_42    feature_43  \\\n",
      "count  ...  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean   ...      0.385468      0.449112      0.202571      0.298621   \n",
      "std    ...      0.492361      0.510514      0.464023      0.484619   \n",
      "min    ...     -2.519065     -1.549892     -2.055758     -2.561680   \n",
      "25%    ...      0.103377      0.093820     -0.063306      0.033173   \n",
      "50%    ...      0.348584      0.381086      0.169752      0.318775   \n",
      "75%    ...      0.666004      0.754328      0.462775      0.590701   \n",
      "max    ...      3.305879      3.089097      2.755982      2.570278   \n",
      "\n",
      "         feature_44    feature_45    feature_46    feature_47    feature_48  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean      -0.325320     -0.600158     -0.609178     -0.695919     -0.483757   \n",
      "std        0.549391      0.648148      0.603203      0.560477      0.534655   \n",
      "min       -2.878262     -5.185454     -2.956195     -3.344382     -3.341399   \n",
      "25%       -0.673691     -0.971989     -0.994527     -1.037685     -0.797180   \n",
      "50%       -0.376889     -0.540003     -0.637544     -0.688341     -0.465977   \n",
      "75%       -0.014890     -0.195001     -0.267438     -0.371834     -0.175463   \n",
      "max        2.705048      2.751204      3.310236      2.372111      2.243955   \n",
      "\n",
      "         feature_49  \n",
      "count  29503.000000  \n",
      "mean      -0.467354  \n",
      "std        0.587391  \n",
      "min       -3.512090  \n",
      "25%       -0.820265  \n",
      "50%       -0.439854  \n",
      "75%       -0.127356  \n",
      "max        2.876692  \n",
      "\n",
      "[8 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# load original dataset\n",
    "data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "\n",
    "# load text8 dataset\n",
    "model = gensim.models.doc2vec.Doc2Vec.load('./gensim_models/doc2vec_model_text8_tweet')\n",
    "\n",
    "for i, j in enumerate(tqdm(data.iloc[:, 0])):\n",
    "    element_splitted = j.split(\" \")\n",
    "    feature_array = model.infer_vector(element_splitted)\n",
    "    for a, b in enumerate(feature_array):\n",
    "        column_name = 'feature_' + str(a)\n",
    "        data.loc[i, column_name] = b\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "data.to_csv('./datasets/tweets_doc2vec_text8_tweet.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29503/29503 [11:56<00:00, 41.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet   feature_0  feature_1  \\\n",
      "0  nytimes thrilled obama talking communist dicta...   0.435439  -0.928838   \n",
      "1  oops thehill trump breaks decades us protocol ...   0.151465   0.004370   \n",
      "2  donald trumpcall taiwan president surprise off...  -0.332151  -0.417230   \n",
      "3                   so trump spoke president taiwan    0.000186  -0.443283   \n",
      "4           trumps wants build hotel resorts taiwan   -0.525013  -0.684377   \n",
      "\n",
      "   feature_2  feature_3  feature_4  feature_5  feature_6  feature_7  \\\n",
      "0   0.394308  -0.796882  -0.128213   0.075368   0.450258   0.005453   \n",
      "1  -0.348230  -0.984871   0.044248   0.063707  -0.822186  -0.687763   \n",
      "2   0.114263   0.229121  -0.321248   0.237009  -0.708201  -0.122863   \n",
      "3  -0.334697   0.222245  -0.547150   0.393903  -0.625978  -0.228578   \n",
      "4   0.134015   0.374476  -0.044499  -0.323775   0.102812  -0.821733   \n",
      "\n",
      "   feature_8  ...  feature_40  feature_41  feature_42  feature_43  feature_44  \\\n",
      "0   0.590217  ...   -0.219913   -0.219888   -0.362273    0.093419   -0.040231   \n",
      "1   0.041908  ...    0.261472   -0.235684   -0.354542   -0.076694   -0.485051   \n",
      "2  -0.068970  ...   -0.502892   -0.088187   -0.028713    0.864549   -0.677641   \n",
      "3   0.502883  ...   -0.444216    0.112485   -0.071087    0.677786   -0.430736   \n",
      "4   0.704817  ...   -0.074893   -0.176632   -0.209429   -0.450111    0.104070   \n",
      "\n",
      "   feature_45  feature_46  feature_47  feature_48  feature_49  \n",
      "0    0.193354   -0.317746   -0.269047   -0.341160    0.062462  \n",
      "1    0.603797   -0.285852   -0.043246   -0.268114   -0.001151  \n",
      "2    1.018224   -0.035905   -0.225179   -0.174115    0.890383  \n",
      "3    0.959454   -0.874815   -0.328046   -0.230804    0.786511  \n",
      "4    0.285203   -0.427264    0.108519    0.431832   -0.048581  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "          feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean       0.189433     -0.360199     -0.279630     -0.214925     -0.376762   \n",
      "std        0.633566      0.706958      0.700893      0.631908      0.641214   \n",
      "min       -3.377652     -4.036743     -5.212138     -3.020107     -3.903072   \n",
      "25%       -0.181394     -0.765315     -0.679460     -0.594374     -0.744753   \n",
      "50%        0.184279     -0.343494     -0.275401     -0.235690     -0.370287   \n",
      "75%        0.550530      0.056215      0.120419      0.140975     -0.007117   \n",
      "max        3.479928      3.056060      3.430920      3.237431      2.876076   \n",
      "\n",
      "          feature_5     feature_6     feature_7     feature_8     feature_9  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean       0.271123     -0.287762     -0.414788      0.206876     -0.003489   \n",
      "std        0.682884      0.659388      0.595476      0.626813      0.615865   \n",
      "min       -3.299067     -4.446279     -3.581687     -3.211934     -3.511380   \n",
      "25%       -0.117761     -0.676573     -0.755138     -0.156420     -0.355904   \n",
      "50%        0.285776     -0.283304     -0.404867      0.204251      0.009274   \n",
      "75%        0.682312      0.100725     -0.070782      0.568295      0.360982   \n",
      "max        3.673052      3.117258      2.558465      4.066347      3.423939   \n",
      "\n",
      "       ...    feature_40    feature_41    feature_42    feature_43  \\\n",
      "count  ...  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean   ...     -0.113705     -0.248019     -0.281574      0.231830   \n",
      "std    ...      0.748359      0.648336      0.627635      0.600019   \n",
      "min    ...     -4.180821     -3.192270     -3.381952     -2.550178   \n",
      "25%    ...     -0.524923     -0.629628     -0.644582     -0.118231   \n",
      "50%    ...     -0.100776     -0.242008     -0.290480      0.226983   \n",
      "75%    ...      0.310225      0.130446      0.074132      0.577566   \n",
      "max    ...      3.771618      2.871151      2.970918      3.442757   \n",
      "\n",
      "         feature_44    feature_45    feature_46    feature_47    feature_48  \\\n",
      "count  29503.000000  29503.000000  29503.000000  29503.000000  29503.000000   \n",
      "mean      -0.119626      0.090397     -0.364392     -0.181637     -0.025345   \n",
      "std        0.660834      0.600134      0.629710      0.616476      0.621292   \n",
      "min       -3.645069     -3.183347     -4.247292     -3.341599     -3.429798   \n",
      "25%       -0.500936     -0.259939     -0.733758     -0.543015     -0.382721   \n",
      "50%       -0.114848      0.087625     -0.355315     -0.185558     -0.017411   \n",
      "75%        0.258969      0.435086      0.004288      0.171466      0.332381   \n",
      "max        2.946306      3.694195      3.068906      3.040299      3.591548   \n",
      "\n",
      "         feature_49  \n",
      "count  29503.000000  \n",
      "mean       0.101573  \n",
      "std        0.714184  \n",
      "min       -3.914716  \n",
      "25%       -0.306935  \n",
      "50%        0.098506  \n",
      "75%        0.518911  \n",
      "max        3.887642  \n",
      "\n",
      "[8 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# load original dataset\n",
    "data = pd.read_csv('./datasets/tweet_stopwords_duplicates_short_removed_space_splitted.csv')\n",
    "\n",
    "# load text8 dataset\n",
    "model = gensim.models.doc2vec.Doc2Vec.load('./gensim_models/doc2vec_model_tweet')\n",
    "\n",
    "for i, j in enumerate(tqdm(data.iloc[:, 0])):\n",
    "    element_splitted = j.split(\" \")\n",
    "    feature_array = model.infer_vector(element_splitted)\n",
    "    for a, b in enumerate(feature_array):\n",
    "        column_name = 'feature_' + str(a)\n",
    "        data.loc[i, column_name] = b\n",
    "\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "data.to_csv('./datasets/tweets_doc2vec_tweet.csv', header=True, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
