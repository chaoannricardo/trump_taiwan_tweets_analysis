{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      " The @nytimes was thrilled by Obama talking to Communist dictator Castro, and horrified by Trump talking to the elected l??e\n"
     ]
    }
   ],
   "source": [
    "# f = pd.read_csv('./datasets/4_original_text_only.csv', sep='\\t')\n",
    "f = pd.read_csv('./datasets/6_retweet_text_only.csv', sep='\\t')\n",
    "print(len(f))\n",
    "tweet = f.iloc[:, 0].tolist()\n",
    "print(tweet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "['', 'the', 'nytimes', 'was', 'thrilled', 'by', 'obama', 'talking', 'to', 'communist', 'dictator', 'castro,', 'and', 'horrified', 'by', 'trump', 'talking', 'to', 'the', 'elected', 'l??e']\n"
     ]
    }
   ],
   "source": [
    "# # 去除stop words, link, account\n",
    "# nltk.download('stopwords')\n",
    "# nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "result1 = []\n",
    "\n",
    "# translation table\n",
    "intab = \"!@#$\\\"\\':\"\n",
    "outtab = \"\"\n",
    "for i in range(len(intab)):\n",
    "    outtab += \" \"\n",
    "trantab = str.maketrans(intab, outtab)\n",
    "\n",
    "\n",
    "for i in range(0, len(tweet)):\n",
    "    tweet_split_list = tweet[i].split(\" \")\n",
    "    words = []\n",
    "    \n",
    "    # convert all words inside the list to be lower case\n",
    "    for j, k in enumerate(tweet_split_list):\n",
    "        tweet_split_list[j] = k.lower()\n",
    "    \n",
    "    for j in range(0, len(tweet_split_list)):\n",
    "        if j == 1:\n",
    "            if '@' not in tweet_split_list[j]:\n",
    "                if 'http' not in tweet_split_list[j]:\n",
    "                    words.append(tweet_split_list[j].lower())\n",
    "#                     if tweet_split_list[j] not in nltk_stopwords and tweet_split_list[j].lower() not in nltk_stopwords and tweet[i][j].upper() not in nltk_stopwords:\n",
    "#                         words.append(tweet_split_list[j])\n",
    "        else:\n",
    "            if 'http' not in tweet_split_list[j]:\n",
    "                tweet_split_list[j] =  tweet_split_list[j].translate(trantab).replace(\" \", \"\")\n",
    "                words.append(tweet_split_list[j])\n",
    "#             if tweet[i][j] not in nltk_stopwords and tweet_split_list[j].lower() not in nltk_stopwords and tweet_split_list[j].upper() not in nltk_stopwords:\n",
    "#                 if 'http' not in tweet_split_list[j]:\n",
    "#                     words.append(tweet_split_list[j])\n",
    "        \n",
    "    result1.append(words)\n",
    "    \n",
    "print(len(result1))\n",
    "print(result1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "[['happy', 'new', 'year', 'everyone', 'newyear', 'family', 'vacation', 'familytime'], ['trump', 'says', 'taiwain', 'leader', 'called', 'him', 'though', 'taiwain', 'paper', 'says', 'trump', 'staffer', 'arranged', 'call', 'hte']]\n"
     ]
    }
   ],
   "source": [
    "# 去除標點符號\n",
    "result2 = []\n",
    "for i in range(0, len(result1)):\n",
    "    words = []\n",
    "    for j in range(0, len(result1[i])):\n",
    "        out = ''.join(c for c in result1[i][j] if c not in string.punctuation)\n",
    "        out = ''.join(x for x in out if ord(x) < 256)\n",
    "        words.append(out)\n",
    "    while '' in words:\n",
    "        words.remove('')\n",
    "    while 'rt' in words:\n",
    "        words.remove('rt')\n",
    "    while '\\uea1d' in words:\n",
    "        words.remove('\\uea1d')\n",
    "    result2.append(words)\n",
    "\n",
    "print(len(result2))\n",
    "print(result2[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614\n",
      "Index(['is_RT', 'retweet_from', 'whole_tweet_text', 'original_text',\n",
      "       'retweet_text'],\n",
      "      dtype='object')\n",
      "614\n",
      "   is_RT     retweet_from                                   whole_tweet_text  \\\n",
      "0      1    SteveSGoddard  RT @SteveSGoddard: The @nytimes was thrilled b...   \n",
      "1      1   DonaldJTrumpJr  RT @DonaldJTrumpJr: Happy new year everyone. #...   \n",
      "2      1  VoteHillary2016  RT @VoteHillary2016: Trump says Taiwain leader...   \n",
      "3      1   NeonKnight1337  RT @NeonKnight1337: Donald Trump's call with T...   \n",
      "4      1    gatewaypundit  RT @gatewaypundit: The Trump Hotel Waikiki loo...   \n",
      "\n",
      "  original_text                                       retweet_text  \\\n",
      "0           NaN   The @nytimes was thrilled by Obama talking to...   \n",
      "1           NaN   Happy new year everyone. #newyear #family #va...   \n",
      "2           NaN   Trump says Taiwain leader called him, though ...   \n",
      "3           NaN   Donald Trump's call with Taiwan president was...   \n",
      "4           NaN   The Trump Hotel Waikiki looks like a lovely r...   \n",
      "\n",
      "                                cleaned_retweet_text  \n",
      "0  the nytimes was thrilled by obama talking to c...  \n",
      "1  happy new year everyone newyear family vacatio...  \n",
      "2  trump says taiwain leader called him though ta...  \n",
      "3  donald trumps call with taiwan president was n...  \n",
      "4  the trump hotel waikiki looks like a lovely re...  \n"
     ]
    }
   ],
   "source": [
    "# f = open('./datasets/7_retweet_text_only_stopwords_removed.csv', \"w+\", encoding=\"utf-8\")\n",
    "# for i in range(0, len(result2)):\n",
    "#     print(result2[i])\n",
    "#     s = \"\"\n",
    "#     for j in range(0, len(result2[i])):\n",
    "#         s += result2[i][j] + ' '\n",
    "#     f.write(s)\n",
    "#     f.write('\\n')\n",
    "# f.close()\n",
    "\n",
    "content_list = []\n",
    "for i, j in enumerate(result2):\n",
    "    content = \" \".join(str(b) for a, b in enumerate(j))\n",
    "    content_list.append(content)\n",
    "\n",
    "# read in the data with whole information\n",
    "original_data = pd.read_csv(\"./datasets/5_retweet_text.csv\", sep='\\t')\n",
    "# original_data = pd.read_csv(\"./datasets/3_original_text.csv\", sep='\\t')\n",
    "print(len(original_data))\n",
    "print(original_data.columns)\n",
    "\n",
    "# add new column\n",
    "original_data.loc[:, 'cleaned_retweet_text'] = content_list\n",
    "# original_data.loc[:, 'cleaned_original_text'] = content_list\n",
    "print(len(original_data))\n",
    "print(original_data.head())\n",
    "\n",
    "original_data.to_csv(\"./datasets/11_retweet_text_only_cleaned.csv\", \n",
    "                     sep=\"\\t\",\n",
    "                    index=None)\n",
    "# original_data.to_csv(\"./datasets/12_original_text_only_cleaned.csv\", \n",
    "#                      sep=\"\\t\",\n",
    "#                     index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['is_RT', 'retweet_from', 'whole_tweet_text', 'original_text',\n",
      "       'retweet_text', 'stopwords_removed_retweet_text'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-91b803e98d8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stopwords_removed_retweet_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0maccount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'without_account'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data = pd.read_csv('./datasets/5_retweet_text.csv', sep='\\t')\n",
    "# print(data.columns)\n",
    "data = pd.read_csv('./datasets/7_retweet_text_only_stopwords_removed.csv', sep='\\t')\n",
    "print(data.columns)\n",
    "\n",
    "for i, j in enumerate(data.loc[:, 'stopwords_removed_retweet_text']):\n",
    "    account = str(data.iloc[i, 1]).lower()\n",
    "    str(j).replace(account, \"\")\n",
    "    data.loc[i, 'without_account'] = j\n",
    "    \n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
