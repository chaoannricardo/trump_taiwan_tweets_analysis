{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31316/31316 [00:00<00:00, 379814.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 61989\n",
      "After:  31316\n",
      "31316\n",
      "31316\n",
      "31316\n",
      "31316\n",
      "31316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv(\"/home/ricardo/Github/trump_taiwan_tweets_analysis/datasets/original_tweet_text_merged_tab.csv\", sep = \"\\t\")\n",
    "\n",
    "# drop duplicates rows\n",
    "# remove duplicates rows\n",
    "print('Before:', len(data))\n",
    "data.drop_duplicates(inplace=True)\n",
    "print('After: ', len(data))\n",
    "\n",
    "# remeber to remove the row after checking the code\n",
    "# data = data.iloc[:50, :]\n",
    "\n",
    "is_retweet_list = []\n",
    "retweet_account_list = []\n",
    "tweet_text_list = []\n",
    "original_text_list = []\n",
    "retweet_text_list = []\n",
    "\n",
    "for i, j in enumerate(tqdm(data.loc[:, 'Tweet'])):\n",
    "    tweet_text_list.append(j)\n",
    "    tweet_split_list = str(j).split(\" \")\n",
    "    # check if the tweet is retweeted\n",
    "    if \"RT\" in tweet_split_list:\n",
    "        is_retweet_list.append(1)\n",
    "        # catch the index of RT\n",
    "        RT_index = tweet_split_list.index('RT')\n",
    "        # original text\n",
    "        original_text = \"\"\n",
    "        for a, b in enumerate(tweet_split_list[:RT_index]):\n",
    "            original_text += \" \" + b\n",
    "        original_text_list.append(original_text)\n",
    "        # Retweeted Text\n",
    "        retweeted_text = \"\"\n",
    "        account_grep = False\n",
    "        for a, b in enumerate(tweet_split_list[RT_index:]):\n",
    "            if len(str(b)) >= 1:\n",
    "                # grep account\n",
    "                if str(b)[0] == \"@\" and account_grep == False:\n",
    "                    account_grep = True\n",
    "                    # eliminate \":\" synbol\n",
    "                    if str(b)[-1] == \":\":\n",
    "                        retweet_account_list.append(b[1:-1])\n",
    "                    else:\n",
    "                        retweet_account_list.append(b[1:])\n",
    "                # do not append 'RT' text\n",
    "                elif b == \"RT\":\n",
    "                    pass\n",
    "                else:\n",
    "                    retweeted_text += \" \" + str(b) \n",
    "        if account_grep == False:\n",
    "            retweet_account_list.append(\"\")\n",
    "        retweet_text_list.append(retweeted_text)\n",
    "    else:\n",
    "        is_retweet_list.append(0)\n",
    "        retweet_account_list.append(\"\")\n",
    "        original_text_list.append(j)\n",
    "        retweet_text_list.append(\"\")\n",
    "\n",
    "print(len(is_retweet_list))\n",
    "print(len(retweet_account_list))\n",
    "print(len(tweet_text_list))\n",
    "print(len(original_text_list))\n",
    "print(len(retweet_text_list))\n",
    "        \n",
    "\n",
    "output_data = pd.DataFrame({\n",
    "    'is_RT':is_retweet_list,\n",
    "    'retweet_from':retweet_account_list,\n",
    "    'whole_tweet_text':tweet_text_list,\n",
    "    'original_text':original_text_list,\n",
    "    'retweet_text':retweet_text_list\n",
    "})\n",
    "        \n",
    "output_data.to_csv(\"~/Github/trump_taiwan_tweets_analysis/datasets/original_splitted.csv\", \n",
    "                   sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31316\n",
      "30567\n",
      "749 \n",
      "\n",
      "30567\n",
      "741 \n",
      "\n",
      "607\n"
     ]
    }
   ],
   "source": [
    "# consider original text and retweet data sperately\n",
    "output_data = output_data.sort_values(by=['is_RT'], ascending=False)\n",
    "print(len(output_data))\n",
    "\n",
    "original_text_data = output_data[output_data['is_RT'] == 0]\n",
    "print(len(original_text_data))\n",
    "retweet_text_data = output_data[output_data['is_RT'] == 1]\n",
    "print(len(retweet_text_data), '\\n')\n",
    "\n",
    "# remove duplicates of both dataframe\n",
    "original_text_data = original_text_data.drop_duplicates(subset='original_text')\n",
    "original_text_data.sort_values(by=['original_text'])\n",
    "print(len(original_text_data))\n",
    "retweet_text_data = retweet_text_data.drop_duplicates(subset='retweet_text')\n",
    "retweet_text_data.sort_values(by=['retweet_text'])\n",
    "print(len(retweet_text_data), '\\n')\n",
    "\n",
    "# man defined duplicates search, elastic similarity threshold = 0.4\n",
    "retweet_text_data.to_csv(\"~/Github/trump_taiwan_tweets_analysis/datasets/retweet_text_without.csv\", \n",
    "                   sep='\\t', index=None)\n",
    "for i, j in enumerate(retweet_text_data.iloc[:, 4]):\n",
    "    content_list = j.split(\" \")\n",
    "    for a, b in enumerate(retweet_text_data.iloc[(i+1):, 4]):\n",
    "        tocheck_content_list = b.split(\" \")\n",
    "        # checking procedure\n",
    "        similar_ratio = (len(content_list + tocheck_content_list) - len(list(set(content_list + tocheck_content_list)))) / len(content_list + tocheck_content_list) \n",
    "        if similar_ratio >= 0.40:\n",
    "#             print(similar_ratio, a, b)\n",
    "            retweet_text_data = retweet_text_data[retweet_text_data['retweet_text'] != b]\n",
    "print(len(retweet_text_data))\n",
    "            \n",
    "\n",
    "# export the datas\n",
    "original_text_data.to_csv(\"~/Github/trump_taiwan_tweets_analysis/datasets/original_text.csv\",\n",
    "                          sep='\\t', index=None)\n",
    "retweet_text_data.to_csv(\"~/Github/trump_taiwan_tweets_analysis/datasets/retweet_text.csv\", \n",
    "                   sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
